Data Science Course: Lectures and Materials
=======


##### Issues: For questions, answers and discussions:
* [Closed and Open Issue List (via pulse)](https://github.com/datadave/GADS9-NYC-Spring2014-Students/pulse#closed-issues)
* [Create a new issue](https://github.com/datadave/GADS9-NYC-Spring2014-Students/issues/new)

##### Viewing Your and Other Student Work:
[iPython Notebook Viewer for this class's student repo](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Students/tree/master/lab_submissions/)

##### Git Workflow and Command Line Tips:
* [Tips](tips/README.md)

# Class Meetings
## Introduction to Data Science
_Monday, 3/31/14_

#### Class Materials
* [lab_01a.md](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson01_intro_to_data_science/lab_01a.md)	
* [lab_01a_example.md](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson01_intro_to_data_science/lab_01a_example.md)
* [lab_01b.md](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson01_intro_to_data_science/lab_01b.md)
* [lec_01.pdf](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson01_intro_to_data_science/lec_01.pdf)

## Data Collection and Extraction
_Wednesday, 4/7/14_

#### Project 1 Introduced
* [Description for Project 1](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/projects/project01.md)

#### Class Materials
* [Lecture](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson02_data_collection_and_extraction/lec02.pdf)
* [Lab 2a](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson02_data_collection_and_extraction/lab02a.md)
* [Lab 2b](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson02_data_collection_and_extraction/lab02b.md)
* [Lab 2b - Code](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson02_data_collection_and_extraction/lab02b.py)

#### Additional Resources:
#####Learning how to use the file pager, `less`

* <a href="http://www.greenwoodsoftware.com/less/faq.html#tricks">Less Homepage</a>

##### Python Documentation

Handy to have this in your bookmarks!

* <a href="https://docs.python.org/2.7/">https://docs.python.org/2.7/</a>

##### Couple extra handy `python` introductions

* <a href="http://www.learnpython.org/">Interactive Python Training</a>
* <a href="https://docs.python.org/2.7/tutorial/index.html">The Python Tutorial</a>


##### Beautiful Soup Tutorials
* <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup Documentation</a>
* <a href="http://www.nyu.edu/projects/politicsdatalab/workshops/BeautifulSoup.pdf">Deck on Beautiful Soup</a>
* <a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/">Greg Reda's Web Scraping 101</a>

##### APIs to play with
* <a href="http://www.pythonapi.com/"> Handy Python APIs</a>
* <a href="https://apigee.com/console/twitter">apigee Console</a>

## Numpy
_Wednesday	4/9/2014_

#### Class Materials
* [IPython Notebook Introduction](http://nbviewer.ipython.org/urls/raw.github.com/datadave/GADS9-NYC-Spring2014-Lectures/master/lessons/lesson03a_numpy/lec_03_IPythonNBIntro.ipynb)
* [Numpy and Pandas Introduction](http://nbviewer.ipython.org/urls/raw.github.com/datadave/GADS9-NYC-Spring2014-Lectures/master/lessons/lesson03a_numpy/lec_03_numpy_and_pandas.ipynb)

#### Additional Resources
* Watch the 5 minute ["Ipython Notebook Tour"](http://ipython.org/notebook.html)
* Review ["What is NumPy"](http://docs.scipy.org/doc/numpy/user/whatisnumpy.html)
* Watch Wes McKinney's 10 minute [Whirlwind Tour of Pandas](http://wesmckinney.com/blog/?p=647) (even once is ok ;-) )
* Another great resource: Review Chapters 1 to 5 of [Julia Evans Cookbook](https://github.com/jvns/pandas-cookbook)


## Pandas
_Monday	4/14/2014_

#### Class Materials
* [Python Data Review](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson03b_pandas/review.md)

* [Lab - Practical Pandas](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson03b_pandas/Lab_03ab.ipynb)
* [Numpy and Pandas Introduction](http://nbviewer.ipython.org/urls/raw.github.com/datadave/GADS9-NYC-Spring2014-Lectures/master/lessons/lesson03a_numpy/lec_03_numpy_and_pandas.ipynb)
* [Pandas Practice](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson03b_pandas/independent_work.md)


## Data Visualization and MatPlotLib
_Wednesday	4/16/2014_

#### Class Materials
[Lecture Notes: Data Visualization](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson04_matplotlib_and_EDA/DataVizLecture_v2.pdf)

[Python Notebook: Plotting with Matplotlib](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson04_matplotlib_and_EDA/Visualization_Instructional_Set.ipynb)

#### Assignments Due
* Complete and submit previous assignments


#### Additional Resources


| Resource | About 
| -------- | ----- 
| [Basic Plotting in Pandas](http://pandas.pydata.org/pandas-docs/stable/visualization.html) |
| [Matplotlib userguide](http://matplotlib.sourceforge.net/users/index.html) |  
| [Matplotlib Gallery](http://matplotlib.org/gallery.html) | Examples with Code 
| [Rougier and Prace EuroSciPy Matplotlib Tutorial](http://www.loria.fr/~rougier/teaching/matplotlib/) | Short Overview 



## Exploratory Data Analysis
_Monday	4/21/2014_
_We'll be reviewing a number of datasets and going through the Data Exploration Process_

The ACES model for Data Exploration:

Letter | Step | Notes
------ | ---- | -----------
A | Acquire the data and Assemble the data frame | Find data, import into Pandas
C | Clean the data frame | Identify and limit columns, rows, indices, dates, etc.
E | Explore global properties | Visualize!  Basic plots and stats appropriate to the data set
S | Subset comparisons | Look at (visualize!) initial emergenet variable relationships and subsets

#### Class Materials
* [EDA Run Through - IMDB](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson05_EDA/explore_consumerpreference.ipynb)

#### Resources
* [EDA with SAT Scores](http://blog.kaggle.com/2013/01/17/getting-started-with-pandas-predicting-sat-scores-for-new-york-city-schools/)
* [Grouping with Pandas](http://pandas.pydata.org/pandas-docs/dev/groupby.html)
* [Data Wrangling Movies](http://nbviewer.ipython.org/github/cs109/content/blob/master/lec_04_wrangling.ipynb)
* [EDA Questions](http://www.itl.nist.gov/div898/handbook/eda/section3/eda32.htm)
* [Volinksy EDA Presentation](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CCYQFjAA&url=http%3A%2F%2Fwww2.research.att.com%2F~volinsky%2FDataMining%2FColumbia2011%2FSlides%2FTopic2-EDAViz.ppt&ei=VA9QU6ODNu2zsASDooCoAQ&usg=AFQjCNEnkeQXZF7l5fIrUGFIrX48qMYUPw&bvm=bv.64764171,d.cWc)


#### Assignments Due
N/A - Please review all prior materials and work on Project 1.


## Presentations, Machine Learning, and Data Science Careers
_Wednesday	4/23/2014_
#### Assignments Due
[Project 1: Scraping, APIs, and Data Visualization](Project 1https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/projects/project01.md)

#### Class Outline
* Selected Presentations of Student Projects
* Discussion of Data Science Careers
* Introduction to Machine Learning


## Linear Regressions
_Monday 4/28/2014_
_We'll be discussing the linear regression algorithm and learn about scoring regression models_

#### Class Materials
* [Lecture Material](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson07_linear_regression/lec07.pdf)
* [Lab Material](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson07_linear_regression/Linear%20Regression.ipynb)

#### Assignments Due
Please submit three optimized models using the `data/day.csv` file in an ipython notebook or python script for each y variable casual, registered, and cnt. Please put this in a `lab_submissions/lab07/yourname` folder.


### More Reading
| Resource | About 
| -------- | ----- 
| [Regressions with Sklearn](http://www.datarobot.com/blog/regularized-linear-regression-with-scikit-learn/) |  
| [Overfitting Regressions](http://shapeofdata.wordpress.com/2013/03/26/general-regression-and-over-fitting/) |  
| [Guide to Logistic Regression](http://blog.yhathq.com/posts/logistic-regression-and-python.html) |  
| [Khan Academy Algebra Review](https://www.khanacademy.org/math/linear-algebra) |
| [MIT OCW](http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/index.htm) |


## Naive Bayes 

[(link to lesson folder)](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/tree/master/lessons/lesson08_probability_naive_bayes)


_Wednesday 4/30/2014_
_We'll be reviewing some basics of probability, developing ways to work with text data, and using a classification algorithm to classify text._

#### Objectives
* Articulate Naive Bayes' advantages, flaws, applications and theoretical foundation
* Explain how Naive Bayes is applied to classify text or Spam
* Be familiar with using the N.B. classifiers in NLTK and SKLearn
* Create a basic Naive Bayes classifier

#### Materials
* [NB_Gender_Names_NLTK:](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson08_probability_naive_bayes/NB_Gender_Names_NLTK.ipynb) Notebook covering basics of Naive Bayes with single features
* [NB_Biebama_NLTK:](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson08_probability_naive_bayes/NB_Biebama_NLTK.ipynb) Demo: Classifying text as Obama or Bieber
* [NB_Movies_SKLearn:](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson08_probability_naive_bayes/NB_Movies_SKLearn.ipynb) Illustration of SK Learn NB functions
* [NB_Movies_NTLK:](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson08_probability_naive_bayes/NB_Movies_NLTK.ipynb) Illustration of NB on text with NLTK

#### Assignments
* Add a feature to the NLTK gender classifier to try and improve performance
* Create a classifier to tell the difference between two authors
* Brainstorm classification topics for projects (due May 14)

#### Follow Up Notes
Based on student feedback:
* [Additional NB Notes](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson08_probability_naive_bayes/AdditionNBNotes.md)

## Classifier Comparison and Logistic Regression
_Wednesday	5/7/2014_

#### Objectives
* Understand how to apply logistic regression to a classification problem
* Create a two dimensional feature space to evalute the performance of classifiers
* Leverage the interoperability of SKLearn classifiers to compare KNN, Naive Bayes, Decision Trees and Logistic Regression on a single classification problem

#### Materials
The lesson notebook provides:

* A brief background on logistic classification
* A mesh function using [np.meshgrid](http://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html) to evaluate the predictive functions on a 2 dimensional feature grid

The intention is to provide a starting template with which to contrast various classifiers on a clean, real-world data set.

[Static Ipython Notebook](http://nbviewer.ipython.org/github/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson10/LogisticClassifying_Update_KNN_DT.ipynb)

#### Assignments
Students are expected add additional classifiers to the notebook, experiment with parameters, and develop conclusions about the differences between classifier performance on the given sample data.


Your Centroid or Mine? An Introduction to K-Means
======================================
_Monday, May 19th_

Humans are good, often too good, at clustering, and its another realm of our intelligence that we can programatically apply to machines.  Toddlers can tell that objects are boats, flags, and doggies -- but how?  

Machine clustering is used to categorize the web, understand galaxies, organize genetic, segment customers, classify mental illness, and detect disease patterns, to name just a few applications.

K Means is a very simple algorithm for classifying that works well and is by far the most widely used.

Here's some resources to get started:

### Recommended Resources
| Title | Author | Type | Length | Difficulty | Description | Rating (1 to 4 Stars)
| ----- | ----- | ---- | ----- | ------ | --- | --- | --- |
|[Cluster Analysis and K-Means](http://www-users.cs.umn.edu/~kumar/dmbook/ch8.pdf)| Kumar, UMN | PDF Excerpt | 40 pages | Intermediate | Good chapter overview on clustering and then section "8.2.1 Basic K-Means Algorithm" gives great K-Means summary.  The rest of 8.2 includes complications wth K-Means and concludes with the optimization math.  If you just want the minimum, read pgs. 498 to 505 | ++++
| [Clustering Overview](http://www.holehouse.org/mlclass/13_Clustering.html) | StanfordML | html page | 3 pages | Intermediate | Good, quick overview of everything | ++++
| [K-Means Clustering](https://www.youtube.com/watch?v=0MQEt10e4NM) | Mathematical Monk | Video | 15 minute | Novice | Good Kahn style overview of math | +++
| [K-Means Wikipedia Entry](http://en.wikipedia.org/wiki/K-means_clustering) | Everyone | Wikipedia | 6 pages | Intermediate | Includes Iris and 'mickey mouse' we'll be looking at. | ++

[Class Lecture](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson13_kmeans/lec13_kmeans_v1.pdf)

Review of Random Forests and the Ensemble Learning Approach
======================================
_Wednesday, May 21st_

We'll wrap up all machine learning material by having a more in detail discussion about the differences between bagging (bootstrapping), boosting, and random forests.

### Recommended Resources
| Title | Author | Type | Length |
| ----- | ----- | ---- | ----- |
|[Ensemble Learning](http://en.wikipedia.org/wiki/Ensemble_learning) | Wikipedia | Article | --- |
|[sklearn doc](http://scikit-learn.org/stable/modules/ensemble.html) | Scikey-learn | Documentation | --- |
|[yhat Blog on Random Forests](http://blog.yhathq.com/posts/random-forests-in-python.html) | yHat | blog article | --- |
|[Ensemble Methods in Machine Learning](http://www.cs.iastate.edu/~jtian/cs573/Papers/Dietterich-ensemble-00.pdf)| Dietterich, Thomas | PDF Journal | 15 pages |
| [A Few Useful Things to Know about Machine Learning](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) | Domingos, Pedro | PDF Journal | 9 pages |
| [Ensemble Methods](http://adataheadsdiary.files.wordpress.com/2013/12/dsdc-ensemble-learing.pdf) | Hyer, Jay | Presentation | 31 Slides |
| [Kaggle Random Forests](http://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-random-forests) | Kaggle | Kaggle | --- |

[Class Lecture](https://github.com/datadave/GADS9-NYC-Spring2014-Lectures/blob/master/lessons/lesson14_ensembles/lesson14_ensembles.pdf?raw=true)

_Updates expected -- See Lesson Folder for further details_

<!--


## KNN and K-Means
_Monday	5/5/2014_
-->
<!--
## Decision Trees


## Principle Component Analysis
_Monday	5/12/2014_

## Review of Machine Learning
_Wednesday	5/14/2014_
-->


<!--
_Monday	5/19/2014_
_Wednesday	5/21/2014_
_Memorial Day	5/26/2014_
_Wednesday	5/28/2014_
_Monday	6/2/2014_
_Wednesday	6/4/2014_
_Monday	6/9/2014_
_Wednesday	6/11/2014_
_Monday	6/16/2014_
_Wednesday	6/18/2014_
-->
