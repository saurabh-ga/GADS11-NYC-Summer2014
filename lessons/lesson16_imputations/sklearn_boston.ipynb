{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Sklearn Imputation\n",
      "\n",
      "_from sklearn documentation. transposed into a notebook for easier reading._"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from sklearn.datasets import load_boston\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "# Set a random seed.\n",
      "rng = np.random.RandomState(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The boston data set included in sklearn is data about Boston housing prices. Like all other sklearn data, it comes in the format sklearn presents all of it's data sets: a python-like dictionary using numpy as the actual data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = load_boston()\n",
      "print dataset.DESCR\n",
      "print dataset.data\n",
      "X_full, y_full = dataset.data, dataset.target\n",
      "n_samples = X_full.shape[0]\n",
      "n_features = X_full.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n",
        "[[  6.32000000e-03   1.80000000e+01   2.31000000e+00 ...,   1.53000000e+01\n",
        "    3.96900000e+02   4.98000000e+00]\n",
        " [  2.73100000e-02   0.00000000e+00   7.07000000e+00 ...,   1.78000000e+01\n",
        "    3.96900000e+02   9.14000000e+00]\n",
        " [  2.72900000e-02   0.00000000e+00   7.07000000e+00 ...,   1.78000000e+01\n",
        "    3.92830000e+02   4.03000000e+00]\n",
        " ..., \n",
        " [  6.07600000e-02   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
        "    3.96900000e+02   5.64000000e+00]\n",
        " [  1.09590000e-01   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
        "    3.93450000e+02   6.48000000e+00]\n",
        " [  4.74100000e-02   0.00000000e+00   1.19300000e+01 ...,   2.10000000e+01\n",
        "    3.96900000e+02   7.88000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below, we're generating an estimation using Random Forests as a regressor (Something to think about: how can you use a classification algorithm as a regression algorithm?). As a sample data set, this is actually pretty clean, so we can just run a regression against the whole data set fine. We return back a fit score (0 to 1) of the regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Estimate the score on the entire dataset, with no missing values\n",
      "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
      "score = cross_val_score(estimator, X_full, y_full).mean()\n",
      "print(\"Score with the entire dataset = %.2f\" % score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score with the entire dataset = 0.56\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To understand how well imputations can actually work, let's literally replace our data with some missing values. Below, our code is setting a missing rate of .75 (aka 75% of our data will be missing), defining the placement of the points that will be missing, and then setting those values to be NA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add missing values in 75% of the lines\n",
      "missing_rate = 0.75\n",
      "n_missing_samples = np.floor(n_samples * missing_rate)\n",
      "missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
      "                                      dtype=np.bool),\n",
      "                             np.ones(n_missing_samples,\n",
      "                                     dtype=np.bool)))\n",
      "rng.shuffle(missing_samples)\n",
      "missing_features = rng.randint(0, n_features, n_missing_samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "/Users/edjoy/anaconda/lib/python2.7/site-packages/numpy/core/numeric.py:178: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  a = empty(shape, dtype, order)\n",
        "-c:9: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's see how well we can still predict when we are missing 75 percent of our data! Our guess? Not that well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Estimate the score without the lines containing missing values\n",
      "X_filtered = X_full[~missing_samples, :]\n",
      "y_filtered = y_full[~missing_samples]\n",
      "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
      "score = cross_val_score(estimator, X_filtered, y_filtered).mean()\n",
      "print(\"Score without the samples containing missing values = %.2f\" % score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score without the samples containing missing values = 0.45\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So from dropping 75% of our data, our cross validated fit score has dropped from .56 to .45: That's a 20% drop in performance. Yikes!\n",
      "\n",
      "One strategy we can use in imputing data is using the \"mean\" strategy, which just replaces any missing value of a given feature with the mean of that feature. This strategy could work okay, though there are others!\n",
      "\n",
      "This also introduces a new module in scikit learn, the Pipeline tool. Pipeline allows us to handle an array of tools we want to work on with the same data set. Pretty nifty!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Estimate the score after imputation of the missing values\n",
      "X_missing = X_full.copy()\n",
      "X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
      "y_missing = y_full.copy()\n",
      "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
      "                                          strategy=\"mean\",\n",
      "                                          axis=0)),\n",
      "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
      "                                                       n_estimators=100))])\n",
      "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
      "print(\"Score after imputation of the missing values = %.2f\" % score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score after imputation of the missing values = 0.56\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above: Not bad! Using mean alone, we've returned back a score of roughly the same as when we weren't missing any data at all."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "On your own"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Check out what other strategies are available in the Imputer tool.\n",
      "2. Given the other strategies, replace each one above. Which ones seems to do the best for this given data set? Which seem to do the worst? Why do you think so?\n",
      "3. Plot the actual Boston data to practice more matplotlib (because we all love matplotlib). Can you come up with a better approach to both:\n",
      "    1. the random missing data\n",
      "    2. a better fit of the prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}